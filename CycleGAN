library(keras)
library(progress)
library(abind)

# Functions ---------------------------------------------------------------


build_generator <- function(){
  
  gf<-32
 
   main_input <- layer_input(shape = img_shape, name = 'main_input')

   d1<-main_input %>% layer_conv_2d(gf, c(4,4),strides = c(2,2), padding = "same", activation = "elu") %>%
    layer_batch_normalization(momentum = 0.8)
   d2<-  layer_conv_2d(d1,gf*2, c(4,4),strides = c(2,2), padding = "same", activation = "elu") %>%
   layer_batch_normalization(momentum = 0.8) 
   d3<-layer_conv_2d(d2,gf*4, c(4,4),strides = c(2,2), padding = "same", activation = "elu") %>%
    layer_batch_normalization(momentum = 0.8) 
   d4 <- layer_conv_2d(d3,gf*8, c(4,4),strides = c(2,2), padding = "same", activation = "elu") %>%
    layer_batch_normalization(momentum = 0.8)


   u1 <- d4 %>% layer_upsampling_2d(size = c(2, 2)) %>%
    layer_conv_2d(gf*4, c(4,4),strides = c(1,1), padding = "same", activation = "relu")
   u1<-layer_concatenate(c(u1,d3),1)

   u2 <- u1 %>% layer_upsampling_2d(size = c(2, 2)) %>%
    layer_conv_2d(gf*2, c(4,4),strides = c(1,1), padding = "same", activation = "relu")
   u2<-layer_concatenate(c(u2,d2),1)

   u3 <- u2 %>% layer_upsampling_2d(size = c(2, 2)) %>%
    layer_conv_2d(gf, c(4,4),strides = c(1,1), padding = "same", activation = "relu")
   u3<-layer_concatenate(c(u3,d1),1)
    u4<-u3 %>% layer_upsampling_2d(size = c(2, 2))

    output_img<-u4 %>% layer_conv_2d(3, c(4,4),strides = c(1,1), padding = "same", activation = "tanh")

   keras_model(main_input, output_img)
   
}

build_discriminator <- function(){
  
  df<-64
  
  
  main_input <- layer_input(shape = img_shape, name = 'main_input')
  
  d1<-main_input %>% layer_conv_2d(df, c(4,4),strides = c(2,2), padding = "same", activation = "elu")
  %>% layer_batch_normalization(momentum = 0.8) 
  d2<-  layer_conv_2d(d1,df*2, c(4,4),strides = c(2,2), padding = "same", activation = "elu") %>%
  layer_batch_normalization(momentum = 0.8) 
  d3<-layer_conv_2d(d2,df*4, c(4,4),strides = c(2,2), padding = "same", activation = "elu") %>%
  layer_batch_normalization(momentum = 0.8) 
  d4 <- layer_conv_2d(d3,df*8, c(4,4),strides = c(2,2), padding = "same", activation = "elu") %>%
  layer_batch_normalization(momentum = 0.8) 
  
  validiy<- d4 %>% 
  layer_conv_2d(1, c(4,4),strides = c(1,1), padding = "same")
  
  keras_model(main_input, validiy)
}



# Parameters --------------------------------------------------------------

# Batch and latent size taken from the paper
epochs <- 50
batch_size <- 100
latent_size <- 100
patch<-(128/2**4)
disc_patch<-c(patch,patch,1)

adam_lr <- 0.00005 
adam_beta_1 <- 0.5
img_shape<-c(3,128,128)
# img_shape<-c(3,128,128)
# Model Definition --------------------------------------------------------
# Build the generator
generatorab <- build_generator()
generatorab %>% compile(
  optimizer = optimizer_adam(lr = adam_lr, beta_1 = adam_beta_1),
  loss = "binary_crossentropy"
)

generatorba <- build_generator()
generatorba %>% compile(
  optimizer = optimizer_adam(lr = adam_lr, beta_1 = adam_beta_1),
  loss = "binary_crossentropy"
)


imga <- layer_input(shape =(c(3,128,128)))
imgb <- layer_input(shape = (c(3,128,128)))

fakeb <- generatorab((imga))
fakea <- generatorba((imgb))

recona <- generatorba((fakeb))
reconb <- generatorab((fakea))



# Build the discriminator
discriminatora <- build_discriminator()
discriminatora %>% compile(
  optimizer = optimizer_adam(lr = adam_lr, beta_1 = adam_beta_1),
  loss = list("mean_squared_error"),metrics='accuracy'
)

discriminatorb <- build_discriminator()
discriminatorb %>% compile(
  optimizer = optimizer_adam(lr = adam_lr, beta_1 = adam_beta_1),
  loss = list("mean_squared_error"),metrics='accuracy'
)

freeze_weights(discriminatora)
freeze_weights(discriminatorb)

valida<-discriminatora(fakea)
validb<-discriminatora(fakeb)



combined <- keras_model(list(imga, imgb), list(valida,validb,fakea,fakeb,recona,reconb))
combined %>% compile(
  optimizer = optimizer_adam(lr = adam_lr, beta_1 = adam_beta_1),loss_weights=list(1,1,0,0,10,10),
  loss = list("mean_squared_error", "mean_squared_error","mean_squared_error","mean_squared_error","mean_squared_error","mean_squared_error")
)

# Data Preparation --------------------------------------------------------

# Loade mnist data, and force it to be of shape (..., 1, 28, 28) with
# range [-1, 1]



# install.packages("imager")
library(imager)
library("EBImage")

# Training ----------------------------------------------------------------
setwd("E:\\gyeongtaek\\kerasr\\apple2orange\\apple2orange\\trainA")
traina<-list()
file_list<-list.files()
for(j in 1:length(file_list)){
da<-load.image(file_list[j])
da2<-da[,,1,]
da3<-resize(da2,128,128)
traina[[j]]<-da3
}

require(abind)
trainA <- abind(traina,along=0)
dim(trainA) <-c(dim(trainA)[1],3,128,128)

setwd("E:\\gyeongtaek\\kerasr\\apple2orange\\apple2orange\\trainb")
trainb<-list()
file_list<-list.files()
for(j in 1:length(file_list)){
  da<-load.image(file_list[j])
  da2<-da[,,1,]
  da3<-resize(da2,128,128)

  trainb[[j]]<-da3
}

require(abind)
trainB <- abind(trainb,along=0)
dim(trainB) <-c(dim(trainB)[1],3,128,128)
dim(trainB)

dim(da3)
dim(da3)
head(da)
da2<-rescale(da,c(0.5))

dim(da2)
setwd("E:\\gyeongtaek\\kerasr\\apple2orange\\apple2orange\\trainB")

for(epoch in 1:epochs){
  
  num_batches <- 30
  pb <- progress_bar$new(
    total = num_batches, 
    format = sprintf("epoch %s/%s :elapsed [:bar] :percent :eta", epoch, epochs),
    clear = FALSE
  )
  
  daloss <- NULL
  dbloss <- NULL
  dloss<-NULL
  g_loss<-NULL
  
  possible_indexes <- 1:num_train
  batch_size <-32
  for(index in 1:num_batches){
    
    pb$tick()
    
    sama<-sample(1:dim(trainA)[1],batch_size)
    samb<-sample(1:dim(trainB)[1],batch_size)
    imga<-trainA[sama,,,]
    imgb<-trainB[samb,,,]
    fake_B <- predict(generatorab,imga)
    fake_A <- predict(generatorba,imgb)
    
    valid<-array(1,dim=c(disc_patch,32))  
    fake<-array(0,dim=c(disc_patch,32))
    
    ak<-predict(discriminatora,imga)

    dim(valid)<-dim(ak)
    dim(fake)<-dim(ak)
   
    # dim(imga)
    da_loss_real <- train_on_batch(
      discriminatora, x = imga, 
      y =valid
    )
    da_loss_fake <- train_on_batch(
      discriminatora, x = fake_A, 
      y =fake
    )

    daloss<-c(daloss,0.5*(mean(unlist(da_loss_fake))+
    mean(unlist(da_loss_real))) )
      
      
    db_loss_real <- train_on_batch(
      discriminatorb, x = imgb, 
      y =valid
    )
    db_loss_fake <- train_on_batch(
      discriminatorb, x = fake_B, 
      y =fake
    )
    
    dbloss<-c(dbloss,0.5*(mean(unlist(db_loss_fake))+
                            mean(unlist(db_loss_real))) )
      
      
    dloss<-c(dloss,0.5*(daloss+dbloss))
    
    sama<-sample(1:dim(trainA)[1],batch_size)
    samb<-sample(1:dim(trainB)[1],batch_size)
    imga<-trainA[sama,,,]
    imgb<-trainB[samb,,,]
    
    
    
    # valid<-array(1,dim=c(disc_patch,32))  
    # fake<-array(0,dim=c(disc_patch,32))
      
  
    
    g_loss0 <- train_on_batch(
      combined, 
      list(imga, imgb),
      list(valid, valid,imga,imgb,imga,imgb)
    )
    
    g_loss<-c(g_loss,g_loss0)
    
  }
  
  cat(sprintf("\nTesting for epoch %02d:", epoch))
  
  # Evaluate the testing loss here
  sama<-sample(1:dim(trainA)[1],5)
  samb<-sample(1:dim(trainB)[1],5)
  imga<-trainA[sama,,,]
  imgb<-trainB[samb,,,]
  
  
  # Get a batch to display
  fakeb <- predict(
    generatorab,    
    imga
  )
  fakea <- predict(
    generatorab,    
    imgb
  )
  reconsta <- predict(
    generatorba,    
    fakeb
  )
  reconstb <- predict(
    generatorab,    
    fakea
  )
  
  
  dim(fakea)<-c(5,128,128,3)
  dim(fakeb)<-c(5,128,128,3)
  dim(reconsta)<-c(5,128,128,3)
  dim(reconstb)<-c(5,128,128,3)
  
  for(k in 1:5){
  oria<-imga[k,,,]
  orib<-imgb[k,,,]
  dim(oria)<-c(128,128,3)
  dim(orib)<-c(128,128,3)
    
  dg<-fakea[k,,,]
  dg2<-fakeb[k,,,]
  dg3<-reconsta[k,,,]
  dg4<-reconstb[k,,,]
  par(mfrow=c(3,2)) 
dim(dg)
round(((oria) + 1.00)/2,4) %>% as.raster() %>%
  plot()
round(((orib) + 1.00)/2,4) %>% as.raster() %>%
  plot()
  round(((dg) + 1.00)/2,4) %>% as.raster() %>%
    plot()
  round(((dg2) + 1.00)/2,4) %>% as.raster() %>%
    plot()
  round(((dg3) + 1.00)/2,4) %>% as.raster() %>%
    plot()
  round(((dg4) + 1.00)/2,4) %>% as.raster() %>%
    plot()
  }
  
}

